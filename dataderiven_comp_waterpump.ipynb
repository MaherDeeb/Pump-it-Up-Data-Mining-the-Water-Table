{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Pump it Up: Data Mining the Water Table](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/page/23/)\n",
    "### Maher Deeb\n",
    "Best score 0.8249 and best ranking is 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "The goal of this project is to build a predective model using data from Taarifa and the Tanzanian Ministry of Water to predict which pumps are functional, which need some repairs, and which don't work at all. Predict one of these three classes is based on a number of variables about what kind of pump is operating, when it was installed, and how it is managed. A smart understanding of which waterpoints will fail can improve maintenance operations and ensure that clean, potable water is available to communities across Tanzania.\n",
    "\n",
    "## Table of content\n",
    "    \n",
    "    1. Abstract\n",
    "    2. Table of content\n",
    "    3. Introduction\n",
    "    3. Data exploring\n",
    "    4. Data cleaning\n",
    "    5. Model training\n",
    "    6. Predection\n",
    "    \n",
    "## Introduction\n",
    "\n",
    "This project is a multi-class classification problem. The goal is to predict which pumps are functional, which need some repairs, and which don't work at all. To solve this problem the data will loaded and explored to address its qualilty and apply data cleaning method to get tidy data. The data will be used to train a classifier based on *Random Forests* method. Finally the model will be tested on a cross validation dataset before prediction the classes of the given testing dataset that should be submitted to the competition website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploring:\n",
    "\n",
    "As a first step the important libraries which are needed to load the datasets and apply pre-and postprossesing will be imported as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import  RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_ini=pd.read_csv('https://s3.amazonaws.com/drivendata/data/7/public/4910797b-ee55-40a7-8668-10efd5c1b960.csv')\n",
    "y_train=pd.read_csv('https://s3.amazonaws.com/drivendata/data/7/public/0bf8bc6e-30d0-4c50-956a-603fc693d966.csv')\n",
    "df_test_ini=pd.read_csv('https://s3.amazonaws.com/drivendata/data/7/public/702ddfc5-68cd-4d1d-a0de-f5f566f76d91.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training raw data contains `59400` records and `40` features. The testing dataset contains `14850` records. By inspecting each feature manually it is possible to tell the following story about the features:\n",
    "\n",
    "\n",
    "### Summary of the features:\n",
    "    \n",
    "1. special features:\n",
    "\n",
    "    - id: unique number refers to a certain pump.\n",
    "    - construction_year: there are some zeros which are invalid data that should be replaced\n",
    "    - num_private: there are some large values. they look like outliers. it contains large amount of 0s as invaild values\n",
    "    - date_recorded: will change to datastamp as follows:\n",
    "\n",
    "```{python}\n",
    "df_train['date_recorded'] = pd.to_datetime(df_train['date_recorded'])\n",
    "df_train['date_recorded']=df_train['date_recorded'].astype('int64')//1e9\n",
    "```\n",
    "    \n",
    "2. numerical features:\n",
    "\n",
    "    - amount_tsh: the amount of water: it contains 0s as invaild values. nonlinear transformation does not help to remove the 0 values\n",
    "    - gps_height: the values look ok no invaild values (it not possible to tell if the 0s are invaild values)\n",
    "    - longitude: there are some 0 values as invalid values and they should be replaced\n",
    "    - latitude: No sign of invalid values\n",
    "    - population: there are some zeros as invalid values\n",
    "\n",
    "3. categorical features:\n",
    "\n",
    "    - region_code: there are some outliers with log transformation the problem can be solved\n",
    "    - district_code: there are some outliers but the log transform it can solved\n",
    "    - funder: 3635 missing values, a lot of categories\n",
    "    - installer: 3655 missing values, a lot of categories\n",
    "    - wpt_name: a lot of categories there are some None values\n",
    "    - payment: limited categories no sign for missing values\n",
    "    - payment_type: limited categories no sign for missing values (there are some 0s)\n",
    "    - water_quality:limited categories no sign for missing values (there are some 0s)\n",
    "    - quality_group:limited categories no sign for missing values (there are some 0s)\n",
    "    - source:limited categories no sign for missing values (there are some 0s)\n",
    "    - source_type:limited categories no sign for missing values (there are some 0s) (high correlated with soruce)\n",
    "    - source_class: alot of 0s-->unknown\n",
    "    - waterpoint_type:limited categories no sign for missing values (there are some 0s)\n",
    "    - waterpoint_type_group:limited categories no sign for missing values (there are some 0s)\n",
    "    - basin:limited categories no sign for missing values\n",
    "    - subvillage:a lot of categories there are no sign of missing values\n",
    "    - region: limited categories no sign for missing values\n",
    "    - lga:a lot of categories there are no sign of missing values\n",
    "    - ward:a lot of categories there are no sign of missing values\n",
    "    - public_meeting:3334 missing values:limited categories there are some signs for missing values (there are some 0s and -1)\n",
    "    - recorded_by: one value no variation\n",
    "    - scheme_management: 3877 missing values limited categories\n",
    "    - scheme_name: 28166 missing values lot of categories\n",
    "    - permit:3056 missing value two categories\n",
    "    - extraction_type:limited categories no sign for missing values\n",
    "    - extraction_type_group:limited categories no sign for missing values\n",
    "    - extraction_type_class:limited categories no sign for missing values\n",
    "    - management:limited categories no sign for missing values\n",
    "    - management_group:limited categories no sign for missing values\n",
    "    - quantity:limited categories no sign for missing values\n",
    "    - quantity_group:limited categories no sign for missing values\n",
    "    \n",
    "### Labels:\n",
    "\n",
    "There are three labels **status_group** that should be predicted:\n",
    "1. functional\n",
    "2. non functional\n",
    "3. functional needs repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedac233616244ffa10796ec15371003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='feature_i', max=39), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_all=list(df_train_ini.columns)\n",
    "def f(feature_i):\n",
    "    print(df_train_ini[features_all[feature_i]].head())  \n",
    "interact(f, feature_i=widgets.IntSlider(min=0,max=39,step=1,value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning:\n",
    "\n",
    "To ensure the same processing on both the training and testing datasets both are merged in one dataset `df_total`. They will be splited again without any problems. The first step is to change the text values in categorical features to numerical values so the correlation between all features can be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame=[df_train_ini,df_test_ini]\n",
    "df_total=pd.concat(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_f=['quantity','management_group','management','extraction_type_class','extraction_type_group',\n",
    "       'extraction_type','permit','scheme_name','scheme_management','public_meeting','ward',\n",
    "       'lga','region','subvillage','basin','waterpoint_type_group','waterpoint_type','source_class',\n",
    "       'source_type','source','quality_group','water_quality','payment_type','payment','wpt_name','installer'\n",
    "       ,'funder','quantity_group']\n",
    "\n",
    "for i in cat_f:\n",
    "    \n",
    "    df_total[i]= df_total[i].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as mentioned before the date will be changed so it can be used as numerical values as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_total['date_recorded'] = pd.to_datetime(df_total['date_recorded'])\n",
    "df_total['date_recorded']=df_total['date_recorded'].astype('int64')//1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid outliers and some possible invalid values nonlinar transformation was applied as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_total['region_code']=np.log10(df_total['region_code']+1)\n",
    "df_total['district_code']=np.log10(df_total['district_code']+1)\n",
    "df_total['gps_height']=np.log10(df_total['gps_height']+100)\n",
    "df_total['num_private']=np.log10(df_total['num_private']+1)\n",
    "df_total['population']=np.log10(df_total['population']+1)\n",
    "df_total['construction_year']=np.log10(df_total['construction_year']+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The histogram of the features can be explored as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ae9f476e514ea4a2f1b757debf4db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='feature_i', max=39), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def g(feature_i):\n",
    "    plt.hist(df_total[features_all[feature_i]], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "    plt.show() \n",
    "    \n",
    "interact(g, feature_i=widgets.IntSlider(min=0,max=39,step=1,value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to check the correlation between the features the following interaction code was used to show high correlated features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28744f21d3ff4d9db9f59dc59ed6066e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=70, description='min_corr', max=99, min=50), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def h(min_corr):\n",
    "    corr_f=df_total.corr()\n",
    "    corr_f[corr_f<min_corr/100]=0\n",
    "    plt.matshow(corr_f)\n",
    "    plt.show()\n",
    "interact(h, min_corr=widgets.IntSlider(min=50,max=99,step=1,value=70));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Dropping columns that are high correlated with other columns or they have large amount of missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_total.drop(['id','recorded_by','source_type','waterpoint_type_group',\n",
    "            'scheme_name','extraction_type_class','quantity_group'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resplit the total dataset after applying data cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14850"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.index=range(0,len(df_total['funder']))    \n",
    "df_train=df_total.loc[0:len(df_train_ini['funder'])-1,:]\n",
    "df_test=df_total.loc[len(df_train_ini['funder']):,:]\n",
    "df_train.index=df_train_ini.index\n",
    "df_test.index=df_test_ini.index\n",
    "len(df_test['funder'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training:\n",
    "In this step the training data will be splited to training and cross validation datasets as follows:\n",
    "It is important to mention that the deep investigation that I did shows that the size of the cross validation set influences the accuracy significantly. The best score was obtained if the `test_size=0.01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_cv, Y_train, y_cv= train_test_split(\n",
    "        df_train,y_train['status_group'], test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier which based on `Random Forest` is defined as follows:\n",
    "In this report only the best hyperparameters values after tuning using the `cross_val_score` that imported from `sklearn.model_selection import`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=600,max_depth=22,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier defined in the step above is used to train the model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=22, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The accuracy of the model on the training dataset can be calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rf: 0.976073870013\n"
     ]
    }
   ],
   "source": [
    "print('train rf:',clf_rf.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model on the cross validation dataset can be calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation rf: 0.828282828283\n"
     ]
    }
   ],
   "source": [
    "print('cross validation rf:',clf_rf.score(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predection\n",
    "\n",
    "In this step the model developed above is used to predict the labels of the given testing dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_sub=df_test_ini[['id']]\n",
    "y_sub_rf=y_sub[['id']]\n",
    "y_sub_rf['status_group']=clf_rf.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally the prediction is saved in `csv` file to submit [here](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/page/23/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_sub_rf.to_csv('submission_MD_rf_best_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "My best score is `0.8249` and my ranking is `#42`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
